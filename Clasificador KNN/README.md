## ğŸ”¹ Clasificador K-Nearest Neighbors (KNN)

El **K-Nearest Neighbors (KNN)** es un algoritmo de aprendizaje supervisado utilizado principalmente para **clasificaciÃ³n** y, en algunos casos, para **regresiÃ³n**.  
Su funcionamiento es simple pero poderoso: para clasificar un nuevo dato, el algoritmo busca los **k vecinos mÃ¡s cercanos** en el conjunto de entrenamiento y asigna la clase mÃ¡s frecuente entre ellos.

### ğŸ”‘ CaracterÃ­sticas principales
- **No paramÃ©trico**: no hace suposiciones sobre la distribuciÃ³n de los datos.  
- **Basado en distancia**: comÃºnmente se usa la distancia **euclidiana**, aunque tambiÃ©n se aplican Manhattan, Minkowski, etc.  
- **HiperparÃ¡metro k**:
  - Valores pequeÃ±os de *k* â†’ modelo sensible al ruido (*sobreajuste*).  
  - Valores grandes de *k* â†’ fronteras de decisiÃ³n demasiado suaves (*subajuste*).  

### âœ… Ventajas
- FÃ¡cil de implementar y comprender.  
- Puede aplicarse en clasificaciÃ³n multiclase.  
- No requiere una fase de entrenamiento compleja.  

### âš ï¸ Desventajas
- Costoso en cÃ³mputo para grandes volÃºmenes de datos.  
- Sensible a la escala de las variables â†’ requiere **normalizaciÃ³n o estandarizaciÃ³n**.  
- Depende mucho de la elecciÃ³n de *k* y de la mÃ©trica de distancia.  

### ğŸ“Š Aplicaciones comunes
- Reconocimiento de imÃ¡genes y patrones.  
- Sistemas de recomendaciÃ³n.  
- DetecciÃ³n de anomalÃ­as.  
- ClasificaciÃ³n de texto. 
